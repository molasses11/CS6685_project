Epoch 1
-------------------------------
loss: 4.602232  [    0/12639]
loss: 4.608751  [ 1216/12639]
loss: 4.599837  [ 2432/12639]
loss: 4.573211  [ 3648/12639]
loss: 4.154710  [ 4864/12639]
loss: 4.169452  [ 6080/12639]
loss: 4.279185  [ 7296/12639]
loss: 4.098464  [ 8512/12639]
loss: 3.948715  [ 9728/12639]
loss: 3.810149  [10944/12639]
loss: 3.613313  [12160/12639]
Test Error: 
 Accuracy: 14.8%, Avg loss: 3.593448 

Epoch 2
-------------------------------
loss: 3.745396  [    0/12639]
loss: 3.480247  [ 1216/12639]
loss: 3.491927  [ 2432/12639]
loss: 3.173898  [ 3648/12639]
loss: 2.879150  [ 4864/12639]
loss: 3.004544  [ 6080/12639]
loss: 3.015072  [ 7296/12639]
loss: 2.530770  [ 8512/12639]
loss: 2.775006  [ 9728/12639]
loss: 2.686395  [10944/12639]
loss: 2.683443  [12160/12639]
Test Error: 
 Accuracy: 40.2%, Avg loss: 2.262126 

Epoch 3
-------------------------------
loss: 2.112514  [    0/12639]
loss: 2.588331  [ 1216/12639]
loss: 2.344451  [ 2432/12639]
loss: 2.109920  [ 3648/12639]
loss: 2.139604  [ 4864/12639]
loss: 2.164868  [ 6080/12639]
loss: 2.008773  [ 7296/12639]
loss: 1.431406  [ 8512/12639]
loss: 2.315037  [ 9728/12639]
loss: 1.807357  [10944/12639]
loss: 1.729040  [12160/12639]
Test Error: 
 Accuracy: 55.0%, Avg loss: 1.759596 

Epoch 4
-------------------------------
loss: 1.770186  [    0/12639]
loss: 1.727416  [ 1216/12639]
loss: 1.413213  [ 2432/12639]
loss: 1.524491  [ 3648/12639]
loss: 1.735091  [ 4864/12639]
loss: 1.192296  [ 6080/12639]
loss: 1.607833  [ 7296/12639]
loss: 1.593184  [ 8512/12639]
loss: 1.610936  [ 9728/12639]
loss: 1.546577  [10944/12639]
loss: 1.515370  [12160/12639]
Test Error: 
 Accuracy: 60.6%, Avg loss: 1.569498 

Epoch 5
-------------------------------
loss: 1.722839  [    0/12639]
loss: 0.780815  [ 1216/12639]
loss: 1.071703  [ 2432/12639]
loss: 0.861271  [ 3648/12639]
loss: 1.524526  [ 4864/12639]
loss: 1.031562  [ 6080/12639]
loss: 1.446778  [ 7296/12639]
loss: 1.142204  [ 8512/12639]
loss: 1.612060  [ 9728/12639]
loss: 1.285968  [10944/12639]
loss: 1.144759  [12160/12639]
Test Error: 
 Accuracy: 63.2%, Avg loss: 1.438585 

Epoch 6
-------------------------------
loss: 0.876639  [    0/12639]
loss: 0.750353  [ 1216/12639]
loss: 0.608522  [ 2432/12639]
loss: 0.916571  [ 3648/12639]
loss: 0.694629  [ 4864/12639]
loss: 0.850130  [ 6080/12639]
loss: 0.924080  [ 7296/12639]
loss: 0.634034  [ 8512/12639]
loss: 0.777269  [ 9728/12639]
loss: 0.933494  [10944/12639]
loss: 0.802263  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 1.510294 

Epoch 7
-------------------------------
loss: 0.467494  [    0/12639]
loss: 0.429903  [ 1216/12639]
loss: 0.189863  [ 2432/12639]
loss: 0.501165  [ 3648/12639]
loss: 0.429714  [ 4864/12639]
loss: 0.437499  [ 6080/12639]
loss: 0.551841  [ 7296/12639]
loss: 0.804982  [ 8512/12639]
loss: 0.616378  [ 9728/12639]
loss: 0.490123  [10944/12639]
loss: 0.343088  [12160/12639]
Test Error: 
 Accuracy: 67.2%, Avg loss: 1.517870 

Epoch 8
-------------------------------
loss: 0.189941  [    0/12639]
loss: 0.139686  [ 1216/12639]
loss: 0.398847  [ 2432/12639]
loss: 0.251632  [ 3648/12639]
loss: 0.393236  [ 4864/12639]
loss: 0.363989  [ 6080/12639]
loss: 0.220826  [ 7296/12639]
loss: 0.306777  [ 8512/12639]
loss: 0.489768  [ 9728/12639]
loss: 0.334814  [10944/12639]
loss: 0.387680  [12160/12639]
Test Error: 
 Accuracy: 65.6%, Avg loss: 1.807226 

Epoch 9
-------------------------------
loss: 0.287933  [    0/12639]
loss: 0.224293  [ 1216/12639]
loss: 0.149344  [ 2432/12639]
loss: 0.289569  [ 3648/12639]
loss: 0.165745  [ 4864/12639]
loss: 0.244571  [ 6080/12639]
loss: 0.233106  [ 7296/12639]
loss: 0.394597  [ 8512/12639]
loss: 0.376753  [ 9728/12639]
loss: 0.161254  [10944/12639]
loss: 0.218210  [12160/12639]
Test Error: 
 Accuracy: 66.2%, Avg loss: 1.973867 

Epoch 10
-------------------------------
loss: 0.336435  [    0/12639]
loss: 0.346059  [ 1216/12639]
loss: 0.101924  [ 2432/12639]
loss: 0.090960  [ 3648/12639]
loss: 0.135759  [ 4864/12639]
loss: 0.268468  [ 6080/12639]
loss: 0.219129  [ 7296/12639]
loss: 0.159380  [ 8512/12639]
loss: 0.091880  [ 9728/12639]
loss: 0.134395  [10944/12639]
loss: 0.182020  [12160/12639]
Test Error: 
 Accuracy: 65.0%, Avg loss: 2.212478 

Epoch 11
-------------------------------
loss: 0.034546  [    0/12639]
loss: 0.025459  [ 1216/12639]
loss: 0.141966  [ 2432/12639]
loss: 0.212886  [ 3648/12639]
loss: 0.106291  [ 4864/12639]
loss: 0.028916  [ 6080/12639]
loss: 0.105648  [ 7296/12639]
loss: 0.103387  [ 8512/12639]
loss: 0.238789  [ 9728/12639]
loss: 0.186755  [10944/12639]
loss: 0.320514  [12160/12639]
Test Error: 
 Accuracy: 65.4%, Avg loss: 2.197158 

Epoch 12
-------------------------------
loss: 0.084535  [    0/12639]
loss: 0.025181  [ 1216/12639]
loss: 0.115808  [ 2432/12639]
loss: 0.100960  [ 3648/12639]
loss: 0.050907  [ 4864/12639]
loss: 0.092394  [ 6080/12639]
loss: 0.251139  [ 7296/12639]
loss: 0.254456  [ 8512/12639]
loss: 0.269917  [ 9728/12639]
loss: 0.120286  [10944/12639]
loss: 0.216288  [12160/12639]
Test Error: 
 Accuracy: 60.6%, Avg loss: 2.793209 

Epoch 13
-------------------------------
loss: 0.095142  [    0/12639]
loss: 0.101290  [ 1216/12639]
loss: 0.075968  [ 2432/12639]
loss: 0.029833  [ 3648/12639]
loss: 0.049947  [ 4864/12639]
loss: 0.080088  [ 6080/12639]
loss: 0.066671  [ 7296/12639]
loss: 0.134428  [ 8512/12639]
loss: 0.361333  [ 9728/12639]
loss: 0.133348  [10944/12639]
loss: 0.090447  [12160/12639]
Test Error: 
 Accuracy: 66.4%, Avg loss: 2.410506 

Epoch 14
-------------------------------
loss: 0.061336  [    0/12639]
loss: 0.047451  [ 1216/12639]
loss: 0.091292  [ 2432/12639]
loss: 0.130908  [ 3648/12639]
loss: 0.179916  [ 4864/12639]
loss: 0.030391  [ 6080/12639]
loss: 0.074360  [ 7296/12639]
loss: 0.120454  [ 8512/12639]
loss: 0.029773  [ 9728/12639]
loss: 0.278582  [10944/12639]
loss: 0.012198  [12160/12639]
Test Error: 
 Accuracy: 67.0%, Avg loss: 2.539288 

Epoch 15
-------------------------------
loss: 0.029475  [    0/12639]
loss: 0.006770  [ 1216/12639]
loss: 0.013982  [ 2432/12639]
loss: 0.011514  [ 3648/12639]
loss: 0.046617  [ 4864/12639]
loss: 0.032375  [ 6080/12639]
loss: 0.118072  [ 7296/12639]
loss: 0.020316  [ 8512/12639]
loss: 0.117389  [ 9728/12639]
loss: 0.184610  [10944/12639]
loss: 0.229987  [12160/12639]
Test Error: 
 Accuracy: 66.2%, Avg loss: 2.600780 

Epoch 16
-------------------------------
loss: 0.038284  [    0/12639]
loss: 0.076231  [ 1216/12639]
loss: 0.018577  [ 2432/12639]
loss: 0.060186  [ 3648/12639]
loss: 0.050866  [ 4864/12639]
loss: 0.026914  [ 6080/12639]
loss: 0.045230  [ 7296/12639]
loss: 0.111369  [ 8512/12639]
loss: 0.037258  [ 9728/12639]
loss: 0.088057  [10944/12639]
loss: 0.079244  [12160/12639]
Test Error: 
 Accuracy: 67.4%, Avg loss: 2.702517 

Epoch 17
-------------------------------
loss: 0.005906  [    0/12639]
loss: 0.021833  [ 1216/12639]
loss: 0.101540  [ 2432/12639]
loss: 0.017541  [ 3648/12639]
loss: 0.068205  [ 4864/12639]
loss: 0.050907  [ 6080/12639]
loss: 0.027547  [ 7296/12639]
loss: 0.103279  [ 8512/12639]
loss: 0.129461  [ 9728/12639]
loss: 0.024513  [10944/12639]
loss: 0.009037  [12160/12639]
Test Error: 
 Accuracy: 67.2%, Avg loss: 2.932581 

Epoch 18
-------------------------------
loss: 0.067953  [    0/12639]
loss: 0.009256  [ 1216/12639]
loss: 0.023508  [ 2432/12639]
loss: 0.089173  [ 3648/12639]
loss: 0.062595  [ 4864/12639]
loss: 0.010733  [ 6080/12639]
loss: 0.118542  [ 7296/12639]
loss: 0.208374  [ 8512/12639]
loss: 0.084391  [ 9728/12639]
loss: 0.107182  [10944/12639]
loss: 0.092720  [12160/12639]
Test Error: 
 Accuracy: 65.6%, Avg loss: 2.748680 

Epoch 19
-------------------------------
loss: 0.009276  [    0/12639]
loss: 0.006446  [ 1216/12639]
loss: 0.009841  [ 2432/12639]
loss: 0.008631  [ 3648/12639]
loss: 0.006429  [ 4864/12639]
loss: 0.001470  [ 6080/12639]
loss: 0.010033  [ 7296/12639]
loss: 0.035742  [ 8512/12639]
loss: 0.118144  [ 9728/12639]
loss: 0.091320  [10944/12639]
loss: 0.059779  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 2.991168 

Epoch 20
-------------------------------
loss: 0.138364  [    0/12639]
loss: 0.023172  [ 1216/12639]
loss: 0.086491  [ 2432/12639]
loss: 0.156214  [ 3648/12639]
loss: 0.136671  [ 4864/12639]
loss: 0.010600  [ 6080/12639]
loss: 0.106484  [ 7296/12639]
loss: 0.236365  [ 8512/12639]
loss: 0.023501  [ 9728/12639]
loss: 0.016699  [10944/12639]
loss: 0.036644  [12160/12639]
Test Error: 
 Accuracy: 67.2%, Avg loss: 2.806240 

Epoch 21
-------------------------------
loss: 0.040119  [    0/12639]
loss: 0.035596  [ 1216/12639]
loss: 0.069074  [ 2432/12639]
loss: 0.003623  [ 3648/12639]
loss: 0.012760  [ 4864/12639]
loss: 0.031317  [ 6080/12639]
loss: 0.072576  [ 7296/12639]
loss: 0.014000  [ 8512/12639]
loss: 0.096114  [ 9728/12639]
loss: 0.055268  [10944/12639]
loss: 0.202835  [12160/12639]
Test Error: 
 Accuracy: 65.8%, Avg loss: 2.841291 

Epoch 22
-------------------------------
loss: 0.003986  [    0/12639]
loss: 0.005556  [ 1216/12639]
loss: 0.017613  [ 2432/12639]
loss: 0.054740  [ 3648/12639]
loss: 0.066762  [ 4864/12639]
loss: 0.040468  [ 6080/12639]
loss: 0.085550  [ 7296/12639]
loss: 0.318482  [ 8512/12639]
loss: 0.196170  [ 9728/12639]
loss: 0.113551  [10944/12639]
loss: 0.096345  [12160/12639]
Test Error: 
 Accuracy: 65.4%, Avg loss: 2.941730 

Epoch 23
-------------------------------
loss: 0.054603  [    0/12639]
loss: 0.239303  [ 1216/12639]
loss: 0.011147  [ 2432/12639]
loss: 0.015447  [ 3648/12639]
loss: 0.022457  [ 4864/12639]
loss: 0.044192  [ 6080/12639]
loss: 0.119972  [ 7296/12639]
loss: 0.033122  [ 8512/12639]
loss: 0.068056  [ 9728/12639]
loss: 0.002070  [10944/12639]
loss: 0.027809  [12160/12639]
Test Error: 
 Accuracy: 66.2%, Avg loss: 2.843650 

Epoch 24
-------------------------------
loss: 0.026934  [    0/12639]
loss: 0.002151  [ 1216/12639]
loss: 0.100698  [ 2432/12639]
loss: 0.010970  [ 3648/12639]
loss: 0.030582  [ 4864/12639]
loss: 0.013942  [ 6080/12639]
loss: 0.203397  [ 7296/12639]
loss: 0.020071  [ 8512/12639]
loss: 0.048295  [ 9728/12639]
loss: 0.024055  [10944/12639]
loss: 0.026967  [12160/12639]
Test Error: 
 Accuracy: 66.6%, Avg loss: 2.825941 

Epoch 25
-------------------------------
loss: 0.040863  [    0/12639]
loss: 0.007539  [ 1216/12639]
loss: 0.054067  [ 2432/12639]
loss: 0.010549  [ 3648/12639]
loss: 0.001852  [ 4864/12639]
loss: 0.028366  [ 6080/12639]
loss: 0.020166  [ 7296/12639]
loss: 0.108505  [ 8512/12639]
loss: 0.033432  [ 9728/12639]
loss: 0.037439  [10944/12639]
loss: 0.040981  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 3.273979 

Epoch 26
-------------------------------
loss: 0.090748  [    0/12639]
loss: 0.014739  [ 1216/12639]
loss: 0.016782  [ 2432/12639]
loss: 0.034446  [ 3648/12639]
loss: 0.049700  [ 4864/12639]
loss: 0.111570  [ 6080/12639]
loss: 0.060053  [ 7296/12639]
loss: 0.036779  [ 8512/12639]
loss: 0.019478  [ 9728/12639]
loss: 0.080408  [10944/12639]
loss: 0.005874  [12160/12639]
Test Error: 
 Accuracy: 64.6%, Avg loss: 3.318301 

Epoch 27
-------------------------------
loss: 0.103534  [    0/12639]
loss: 0.041412  [ 1216/12639]
loss: 0.082337  [ 2432/12639]
loss: 0.074018  [ 3648/12639]
loss: 0.032780  [ 4864/12639]
loss: 0.104602  [ 6080/12639]
loss: 0.185414  [ 7296/12639]
loss: 0.088178  [ 8512/12639]
loss: 0.035577  [ 9728/12639]
loss: 0.067594  [10944/12639]
loss: 0.007815  [12160/12639]
Test Error: 
 Accuracy: 64.6%, Avg loss: 3.131842 

Epoch 28
-------------------------------
loss: 0.079735  [    0/12639]
loss: 0.020057  [ 1216/12639]
loss: 0.158277  [ 2432/12639]
loss: 0.074853  [ 3648/12639]
loss: 0.004546  [ 4864/12639]
loss: 0.006097  [ 6080/12639]
loss: 0.160291  [ 7296/12639]
loss: 0.055648  [ 8512/12639]
loss: 0.019145  [ 9728/12639]
loss: 0.056176  [10944/12639]
loss: 0.005375  [12160/12639]
Test Error: 
 Accuracy: 63.0%, Avg loss: 3.375234 

Epoch 29
-------------------------------
loss: 0.096466  [    0/12639]
loss: 0.015934  [ 1216/12639]
loss: 0.019614  [ 2432/12639]
loss: 0.054078  [ 3648/12639]
loss: 0.089188  [ 4864/12639]
loss: 0.106792  [ 6080/12639]
loss: 0.012427  [ 7296/12639]
loss: 0.044227  [ 8512/12639]
loss: 0.003726  [ 9728/12639]
loss: 0.032485  [10944/12639]
loss: 0.088087  [12160/12639]
Test Error: 
 Accuracy: 67.2%, Avg loss: 3.319244 

Epoch 30
-------------------------------
loss: 0.011525  [    0/12639]
loss: 0.016057  [ 1216/12639]
loss: 0.030569  [ 2432/12639]
loss: 0.003082  [ 3648/12639]
loss: 0.001635  [ 4864/12639]
loss: 0.030554  [ 6080/12639]
loss: 0.156876  [ 7296/12639]
loss: 0.241289  [ 8512/12639]
loss: 0.194574  [ 9728/12639]
loss: 0.006236  [10944/12639]
loss: 0.016475  [12160/12639]
Test Error: 
 Accuracy: 63.2%, Avg loss: 3.394583 

Epoch 31
-------------------------------
loss: 0.002341  [    0/12639]
loss: 0.040125  [ 1216/12639]
loss: 0.095953  [ 2432/12639]
loss: 0.611195  [ 3648/12639]
loss: 0.024257  [ 4864/12639]
loss: 0.029759  [ 6080/12639]
loss: 0.009591  [ 7296/12639]
loss: 0.004139  [ 8512/12639]
loss: 0.003762  [ 9728/12639]
loss: 0.007020  [10944/12639]
loss: 0.031938  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 3.599230 

Epoch 32
-------------------------------
loss: 0.008675  [    0/12639]
loss: 0.144945  [ 1216/12639]
loss: 0.026227  [ 2432/12639]
loss: 0.037085  [ 3648/12639]
loss: 0.008978  [ 4864/12639]
loss: 0.086236  [ 6080/12639]
loss: 0.029408  [ 7296/12639]
loss: 0.018860  [ 8512/12639]
loss: 0.117960  [ 9728/12639]
loss: 0.060519  [10944/12639]
loss: 0.027247  [12160/12639]
Test Error: 
 Accuracy: 63.2%, Avg loss: 3.134092 

Epoch 33
-------------------------------
loss: 0.063307  [    0/12639]
loss: 0.116263  [ 1216/12639]
loss: 0.027889  [ 2432/12639]
loss: 0.055341  [ 3648/12639]
loss: 0.081570  [ 4864/12639]
loss: 0.004925  [ 6080/12639]
loss: 0.045545  [ 7296/12639]
loss: 0.152822  [ 8512/12639]
loss: 0.003586  [ 9728/12639]
loss: 0.037821  [10944/12639]
loss: 0.009069  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 3.343336 

Epoch 34
-------------------------------
loss: 0.002085  [    0/12639]
loss: 0.016174  [ 1216/12639]
loss: 0.127265  [ 2432/12639]
loss: 0.002826  [ 3648/12639]
loss: 0.171357  [ 4864/12639]
loss: 0.007554  [ 6080/12639]
loss: 0.014459  [ 7296/12639]
loss: 0.029828  [ 8512/12639]
loss: 0.107271  [ 9728/12639]
loss: 0.008646  [10944/12639]
loss: 0.027244  [12160/12639]
Test Error: 
 Accuracy: 63.0%, Avg loss: 3.375475 

Epoch 35
-------------------------------
loss: 0.013673  [    0/12639]
loss: 0.106004  [ 1216/12639]
loss: 0.009754  [ 2432/12639]
loss: 0.004661  [ 3648/12639]
loss: 0.015089  [ 4864/12639]
loss: 0.007043  [ 6080/12639]
loss: 0.054350  [ 7296/12639]
loss: 0.094218  [ 8512/12639]
loss: 0.041691  [ 9728/12639]
loss: 0.028117  [10944/12639]
loss: 0.140505  [12160/12639]
Test Error: 
 Accuracy: 67.4%, Avg loss: 2.939074 

Epoch 36
-------------------------------
loss: 0.001536  [    0/12639]
loss: 0.001634  [ 1216/12639]
loss: 0.006886  [ 2432/12639]
loss: 0.013594  [ 3648/12639]
loss: 0.002654  [ 4864/12639]
loss: 0.070633  [ 6080/12639]
loss: 0.000925  [ 7296/12639]
loss: 0.020008  [ 8512/12639]
loss: 0.008397  [ 9728/12639]
loss: 0.016833  [10944/12639]
loss: 0.118155  [12160/12639]
Test Error: 
 Accuracy: 66.4%, Avg loss: 3.289772 

Epoch 37
-------------------------------
loss: 0.000987  [    0/12639]
loss: 0.017841  [ 1216/12639]
loss: 0.002057  [ 2432/12639]
loss: 0.010759  [ 3648/12639]
loss: 0.004967  [ 4864/12639]
loss: 0.005117  [ 6080/12639]
loss: 0.004028  [ 7296/12639]
loss: 0.008465  [ 8512/12639]
loss: 0.010282  [ 9728/12639]
loss: 0.006110  [10944/12639]
loss: 0.002050  [12160/12639]
Test Error: 
 Accuracy: 64.0%, Avg loss: 3.350712 

Epoch 38
-------------------------------
loss: 0.002654  [    0/12639]
loss: 0.015931  [ 1216/12639]
loss: 0.043546  [ 2432/12639]
loss: 0.032333  [ 3648/12639]
loss: 0.155273  [ 4864/12639]
loss: 0.095428  [ 6080/12639]
loss: 0.062525  [ 7296/12639]
loss: 0.209781  [ 8512/12639]
loss: 0.024765  [ 9728/12639]
loss: 0.140594  [10944/12639]
loss: 0.020468  [12160/12639]
Test Error: 
 Accuracy: 65.4%, Avg loss: 3.357172 

Epoch 39
-------------------------------
loss: 0.043910  [    0/12639]
loss: 0.029448  [ 1216/12639]
loss: 0.010673  [ 2432/12639]
loss: 0.050847  [ 3648/12639]
loss: 0.034125  [ 4864/12639]
loss: 0.006356  [ 6080/12639]
loss: 0.031920  [ 7296/12639]
loss: 0.041975  [ 8512/12639]
loss: 0.048486  [ 9728/12639]
loss: 0.017618  [10944/12639]
loss: 0.144486  [12160/12639]
Test Error: 
 Accuracy: 65.0%, Avg loss: 3.202635 

Epoch 40
-------------------------------
loss: 0.053482  [    0/12639]
loss: 0.002428  [ 1216/12639]
loss: 0.086127  [ 2432/12639]
loss: 0.037929  [ 3648/12639]
loss: 0.077702  [ 4864/12639]
loss: 0.085508  [ 6080/12639]
loss: 0.004892  [ 7296/12639]
loss: 0.009858  [ 8512/12639]
loss: 0.017332  [ 9728/12639]
loss: 0.079794  [10944/12639]
loss: 0.179844  [12160/12639]
Test Error: 
 Accuracy: 64.8%, Avg loss: 3.192143 

Epoch 41
-------------------------------
loss: 0.004114  [    0/12639]
loss: 0.001865  [ 1216/12639]
loss: 0.033192  [ 2432/12639]
loss: 0.018612  [ 3648/12639]
loss: 0.000102  [ 4864/12639]
loss: 0.020802  [ 6080/12639]
loss: 0.002543  [ 7296/12639]
loss: 0.001583  [ 8512/12639]
loss: 0.053588  [ 9728/12639]
loss: 0.064707  [10944/12639]
loss: 0.016144  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 3.633821 

Epoch 42
-------------------------------
loss: 0.001045  [    0/12639]
loss: 0.007082  [ 1216/12639]
loss: 0.161372  [ 2432/12639]
loss: 0.073239  [ 3648/12639]
loss: 0.153402  [ 4864/12639]
loss: 0.098396  [ 6080/12639]
loss: 0.069081  [ 7296/12639]
loss: 0.005051  [ 8512/12639]
loss: 0.003779  [ 9728/12639]
loss: 0.303133  [10944/12639]
loss: 0.046912  [12160/12639]
Test Error: 
 Accuracy: 65.8%, Avg loss: 3.819272 

Epoch 43
-------------------------------
loss: 0.052648  [    0/12639]
loss: 0.150035  [ 1216/12639]
loss: 0.009667  [ 2432/12639]
loss: 0.003030  [ 3648/12639]
loss: 0.114616  [ 4864/12639]
loss: 0.019700  [ 6080/12639]
loss: 0.016208  [ 7296/12639]
loss: 0.006857  [ 8512/12639]
loss: 0.043718  [ 9728/12639]
loss: 0.050886  [10944/12639]
loss: 0.024410  [12160/12639]
Test Error: 
 Accuracy: 65.6%, Avg loss: 3.252122 

Epoch 44
-------------------------------
loss: 0.031234  [    0/12639]
loss: 0.003176  [ 1216/12639]
loss: 0.005258  [ 2432/12639]
loss: 0.003836  [ 3648/12639]
loss: 0.023409  [ 4864/12639]
loss: 0.045410  [ 6080/12639]
loss: 0.016457  [ 7296/12639]
loss: 0.000515  [ 8512/12639]
loss: 0.154555  [ 9728/12639]
loss: 0.036410  [10944/12639]
loss: 0.001376  [12160/12639]
Test Error: 
 Accuracy: 66.8%, Avg loss: 3.540388 

Epoch 45
-------------------------------
loss: 0.000609  [    0/12639]
loss: 0.239952  [ 1216/12639]
loss: 0.006377  [ 2432/12639]
loss: 0.009129  [ 3648/12639]
loss: 0.082810  [ 4864/12639]
loss: 0.000301  [ 6080/12639]
loss: 0.016495  [ 7296/12639]
loss: 0.004242  [ 8512/12639]
loss: 0.001844  [ 9728/12639]
loss: 0.025520  [10944/12639]
loss: 0.007826  [12160/12639]
Test Error: 
 Accuracy: 64.0%, Avg loss: 3.662156 

Epoch 46
-------------------------------
loss: 0.049591  [    0/12639]
loss: 0.001357  [ 1216/12639]
loss: 0.003004  [ 2432/12639]
loss: 0.001095  [ 3648/12639]
loss: 0.025720  [ 4864/12639]
loss: 0.001656  [ 6080/12639]
loss: 0.029974  [ 7296/12639]
loss: 0.048871  [ 8512/12639]
loss: 0.000557  [ 9728/12639]
loss: 0.002663  [10944/12639]
loss: 0.000568  [12160/12639]
Test Error: 
 Accuracy: 65.8%, Avg loss: 3.593859 

Epoch 47
-------------------------------
loss: 0.006700  [    0/12639]
loss: 0.009354  [ 1216/12639]
loss: 0.002963  [ 2432/12639]
loss: 0.001832  [ 3648/12639]
loss: 0.014731  [ 4864/12639]
loss: 0.000309  [ 6080/12639]
loss: 0.076833  [ 7296/12639]
loss: 0.051885  [ 8512/12639]
loss: 0.252087  [ 9728/12639]
loss: 0.007256  [10944/12639]
loss: 0.000828  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 3.693636 

Epoch 48
-------------------------------
loss: 0.129438  [    0/12639]
loss: 0.012976  [ 1216/12639]
loss: 0.030684  [ 2432/12639]
loss: 0.000611  [ 3648/12639]
loss: 0.082609  [ 4864/12639]
loss: 0.000323  [ 6080/12639]
loss: 0.000823  [ 7296/12639]
loss: 0.027005  [ 8512/12639]
loss: 0.006532  [ 9728/12639]
loss: 0.001953  [10944/12639]
loss: 0.032356  [12160/12639]
Test Error: 
 Accuracy: 67.0%, Avg loss: 3.577278 

Epoch 49
-------------------------------
loss: 0.014287  [    0/12639]
loss: 0.005201  [ 1216/12639]
loss: 0.017844  [ 2432/12639]
loss: 0.003143  [ 3648/12639]
loss: 0.001092  [ 4864/12639]
loss: 0.001238  [ 6080/12639]
loss: 0.007557  [ 7296/12639]
loss: 0.008419  [ 8512/12639]
loss: 0.000850  [ 9728/12639]
loss: 0.076051  [10944/12639]
loss: 0.039306  [12160/12639]
Test Error: 
 Accuracy: 63.6%, Avg loss: 4.427467 

Epoch 50
-------------------------------
loss: 0.003396  [    0/12639]
loss: 0.015787  [ 1216/12639]
loss: 0.052875  [ 2432/12639]
loss: 0.218583  [ 3648/12639]
loss: 0.318389  [ 4864/12639]
loss: 0.001808  [ 6080/12639]
loss: 0.053382  [ 7296/12639]
loss: 0.108081  [ 8512/12639]
loss: 0.009150  [ 9728/12639]
loss: 0.011657  [10944/12639]
loss: 0.016596  [12160/12639]
Test Error: 
 Accuracy: 65.2%, Avg loss: 3.905789 

Done!
